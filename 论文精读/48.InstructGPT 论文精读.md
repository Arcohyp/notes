https://www.bilibili.com/video/BV1hd4y187CR/?spm_id_from=333.788&vd_source=bbca381483664de7941cac6af725c6df

Align:对一下（工作）

Training language models to follow instructions with human feedback

## 前言
语言模型的数据很杂，你不知道什么样的数据有效，同时你也很难控制整个模型的好坏

1.有效性

文本里没有的东西，模型很难学会
（或者说时效性，如果数据集不是实时更新或者在线，那么没办法进行即时信息的反馈）

2.安全性

模型输出的内容应当安全，避免危险内容

## 摘要部分
首先标一个数据，把问题和答案都写出来，训练了一个模型。

又做了一个排序的数据集，排序的内容是模型的各种输出，用使用人类反馈的强化学习去训练一个模型
