## 1.Efficient PEFT 慢>快，变得lightweight
parameter efficient fine tuning

**AIM: adapting image models for efficient video action recognition**

不断地在原有模型上增加小的adaption模块，并锁住预训练的clip模型参数
训练过程中只更新这些adaption模块中的参数以降低训练难度（但依然很难）

## 2.Existing stuff(pretrained model) new directions
能用别人的模型直接用，别折磨
**unsupervised semantic segmentation with self-supervised object-centric representations**
有观点认为，人类看待物体的视角是有聚焦轻重的，故有object-centric learning
给定一个物体的图片，使用DeepUSPS提取其中可能的物品的Mask信息Salient Mask，
利用Salient Mask从原图中将物体扣出来，并resize正常大小224*224给DINO
再使用DINO还给我们一个1024*1024的global representation(特征)
再将特征丢给cluster，生成noisy pseudo-masks(虽然不知道类别是什么，但是有编号，编号就能和mask有个对应)
可以训练一个semantic semitation network，无论使用PSP.Net还是DeepLab V3都可以

	Language Guided Segmentation
	Swing模型处理地理图片remote sensing
	FewShot ZeroShot Fine-Tuning
	Causality Learning，因果学习
	Feedforward Network,FFNet
	In-Context Learning, Chain of Thought Prompting

## 3.plug and play 即插即用的模块 新的目标函数，loss，data augmentation的方法
Non-Local Module, ResNet后面加一个Non-Local
目标函数，比如正常Loss > focal loss
输入端 数据增强 mixup
如果只是为了证明东西有效，不需要达到SOTA，多个数据集上有统一的提升就可以了

**MixGen: A New Multi-Modal Data Augmentation**
knowledge distillation 知识蒸馏 
VLMo
color jittering 谨慎使用 random flip

如果做数据增强，原本的图像文本对就会不匹配，这是因为数据增强操作会给原有的数据增加/减少信息
如果我们想要保存最多的信息：

	图像：mixup 对于图像处理的方式，直接使用线性插值的方式，
	文本：random erasing/insertion back translation，简单的想法就是，直接把两个句子拼接在一起

mixgen的思路就是，把两张图片加一起，文本也加一起，直接生成新的数据样本
应用于下游任务，mixgen的形式可能会有所改变：

	1)VQA:一张图片，一个问题，一个答案（2个文本）
	2)Visual entailment：2张图片，一个文本

## 4.Dataset, evaluation and survey
bigdetection，将多个数据集进行merge，这个取决于要做预训练还是做下游任务，最终生成了一个600类的目标检测
开源 amazon science github 搜索 bigdetection就可以了

**A comprehensive study of deep video action recognition综述论文**
